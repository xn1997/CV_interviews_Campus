## 随机裁剪

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200909225025823.png#pic_center)

对图片随机0.6~1.0**比率大小的区域进行裁剪**。

然后resize到固定大小。

### torch.API

```python
torchvision.transforms.RandomCrop(size,padding=None,pad_if_need=False,fill=0,padding_mode='constant')
```

```python
 transforms.RandomCrop(32, padding=4),#每边填充4，如把32*32填充至40*40，再随机裁剪出32*32的大小
```

size：裁剪的大小，可以是tuple

padding：将原图填充多少后，再裁剪，保证可以裁剪到边缘图像。

### 原因

假设类别C的主要特征为F，采集得到的图片包含背景噪声B，即现在C表示为(F, B)，我们本来期望学习关系$f^ ∗ : F → C$​，结果现在可能学习成关系$\hat{f} : (F, B) \to C $​，从而陷入过拟合。而**图像裁剪可以主要保留主要特征F，而裁减掉背景噪声B，从而避免噪声的过拟合影响**。

[深度学习在训练时对图片随机剪裁（random crop）](https://blog.csdn.net/u014134327/article/details/110677326)

## mixup

<img src="https://img-blog.csdnimg.cn/20200523145010477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzU2ODY2,size_16,color_FFFFFF,t_70" alt="mixup增强的样例1" style="zoom:50%;" />

1. 两张图片按0.5的比例叠加
2. 分类标签：直接按0.5比例设置标签
   位置标签：保持原值，不做任何变化

注意点：

**叠加后的图片，取两张图片宽高的最大值**，确保新图片可以放下两张图片，同时也不需要对标签做任何转换，很方便。
(600,800)和(900,700)两张图融合得到的新图大小是(900,800)，新增的部分取零

### 原因

增加了样本数量，丰富了目标背景，提高模型的泛化能力。

## CutMix

CutMix是CutOut和Mixup的结合，将图片的一部分区域擦除并随机填充训练集中的其他数据区域像素值。（和RandomPatch基本上一模一样）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200611195957706.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODY4ODM5OQ==,size_16,color_FFFFFF,t_70)

## Random Erasing

<img src="https://img-blog.csdnimg.cn/20200510143522485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTU2MDQwMg==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:50%;" />

具体操作就是：**随机选择一个区域，然后采用随机值进行覆盖，模拟遮挡场景**。

1. 对于图像I，随机擦除与否是以一定概率p进行的；
2. 矩形框与图像I的**面积比例**是随机的；
3. 矩形框的位置（如，**左上角坐标**或中心坐标）是随机的；
4. 矩形框的**宽高比**是随机的；
5. **填充值是随机的**，其范围为$[0,255]$​。（论文中给出4中填充值：随机值、数据集的均值、0、255，但通过实验发现，**随机值填充方式的效果最好**。）

### 原因

**把物体遮挡一部分后依然能够分类正确，那么肯定会迫使网络利用局部未遮挡的数据进行识别，加大了训练难度，一定程度会提高泛化能力**

## cutout

<img src="https://img-blog.csdnimg.cn/20200510161030981.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTU2MDQwMg==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom:50%;" />

和RE非常像，区别如下：

1. cutout**只有正方形**。因为作者发现区域的大小比形状更重要。
2. cutout区域，**不一定完全在原图中**，所以在边缘位置，擦除的区域不一定是正方形，比如上图中右下角那个图，就是个长方形。
3. **填充值只有0**或其他纯色填充。

注意：torchvision.transforms.Cutout并不只是，正方形，也可以是任意矩形，感觉和RE一样，只是用的纯色填充罢了，如下图所示。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200909224842991.png#pic_center)![在这里插入图片描述](https://img-blog.csdnimg.cn/20200909224859788.png#pic_center)

### 原因

同RE

**把物体遮挡一部分后依然能够分类正确，那么肯定会迫使网络利用局部未遮挡的数据进行识别，加大了训练难度，一定程度会提高泛化能力**

## mosaic

1. 随机翻转
2. 随机缩放
3. HSV空间的色域变换
4. 图片贴在四个角
5. 对图片进行分割，去掉重叠的部分
   分割线为边长0.3到0.6之间(随机)
   缩放比例为1-0.3到0.7+0.2之间

1.每次读取四张图片![img](https://upload-images.jianshu.io/upload_images/15903726-e16512919a609216.png?imageMogr2/auto-orient/strip|imageView2/2/w/552/format/webp)2.分别对四张图片进行翻转、缩放、色域变化等，并且按照四个方向位置摆好。![img](https://upload-images.jianshu.io/upload_images/15903726-b8b3178cbfb63318.png?imageMogr2/auto-orient/strip|imageView2/2/w/408/format/webp)3.进行图片的组合和框的组合![img](https://upload-images.jianshu.io/upload_images/15903726-ca520749f51956da.png?imageMogr2/auto-orient/strip|imageView2/2/w/416/format/webp)

### 原因

1. **丰富数据集：**随机使用**4张图片**，**随机缩放，再随机分布**进行拼接，大大丰富了检测数据集，特别是随机缩放**增加了很多小目标**，让网络的鲁棒性更好。
2. **减少GPU：**可能会有人说，随机缩放，普通的数据增强也可以做，但作者考虑到很多人可能只有一个GPU，因此Mosaic增强训练时，**可以直接计算4张图片的数据，使得Mini-batch大小并不需要很大**，一个GPU就可以达到比较好的效果。

[数据增强：Mixup,Cutout,CutMix | Mosaic](https://www.jianshu.com/p/639f9ecc1328)

## copypaste

将实例分割的目标，随机贴在不同的图片上，以增加数据的多样性。

## GridMask

Random Erase、CutOut有可能<u>把图像的可判别区域全部删除或者保留，引入噪声并且效果不佳</u>。**结构化drop操作，例如均匀分布地删除正方形区域**，并且通过控制密度和size参数，来达到平衡，密度就是正方形个数，size就是正方形大小。

![GridMask](https://img-blog.csdnimg.cn/20200611183520800.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODY4ODM5OQ==,size_16,color_FFFFFF,t_70)

# bag of freebies

### 数据扩增

- 随机缩放

- 随机裁剪

- 随机反转

- 随机旋转

  

- 色彩扰动

  - 亮度
  - 对比度
  - 饱和度
  - 色调
  - 高斯噪声

  

- 随机擦除（random erasing）

- cutout

- GridMask

### 多图融合

- Mixup
- CutMix
- Mosaic

### 正则化

类似于输入图像遮挡，在特征图上丢弃某些信息的方法常叫做正则化，最终目的还是防止模型过拟合

- Dropout
- DropBlock

### 数据不平衡的方法

- OHEM
- Focal loss

### 其他方法

- label smooth
- 知识蒸馏——获得更好的soft label
- CIOU loss

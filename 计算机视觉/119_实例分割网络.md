## Mask R-CNN

![img](https://pic1.zhimg.com/80/v2-c94b96c9f8e121f4e4e9719fb4d85f30_720w.jpg)

单独添加了一个和cls/reg并行的mask分支，

通道数就是cls的个数，即为**每一类预测一个mask**。

mask的特征图都要大于cls/reg，因为mask是像素级别的，分辨率应该高些。

最后使用的下图右边的结构，因为有FPN效果更好。

![img](https://pic2.zhimg.com/80/v2-e19cc9cf2e3939ca0f6476b1d7727dc5_720w.jpg)

## SOLOv1

<img src="https://pic1.zhimg.com/80/v2-a26d788828a9260c695db0a246d7cdc0_720w.jpg" alt="img" style="zoom:200%;" />

1. 直接假设图中有S×S个目标，共有C个类别

2. 两个分支
   分类分支：S×S×C。即每个实例所属于的类别。
   掩膜分支：H×W×S×S。即每个实例的掩膜图。
   从而由分类分支确定那个实例是有物体的，从而从掩膜分支找出对应的掩膜图。

## SOLOv2

![img](https://pic2.zhimg.com/80/v2-00603cd5ee2952fd5dc16a2c634764e1_720w.jpg)

**主要目标：v1参数量太大，v2减少计算量。**

SOLO v2中的mask branch 被分解为mask kernel branch和mask feature branch，分别对应卷积核的学习和特征的学习。**两个分支的输出最终组合成整个mask branch的输出**。

**Mask kernel branch**

Mask kernel branch用来学习卷积核，即分类器的权重，有点类似STN和Dynamic Filter的思路。这里输入为H×W×E的特征F，其中E是输入特征的通道数；输出为卷积核S×S×D，其中S是划分的网格数目，D是卷积核的通道数。对应关系如下：1×1×E的卷积核，则D=E，3×3×E的卷积核，则D=9E，以此类推。注意到这里不需要激活函数。

1. 输出（以3×3卷积核为例）：
   由分类分支确定S×S大小的特征图中，哪个位置有实例。
   从kernel branch中<u>找出对应位置的特征</u>（D维=9E）；
   将D维特征向量<u>reshape成3×3×E</u>的卷积核；
   利用这个卷积核对feature branch进行<u>卷积得到的就是掩膜图</u>。


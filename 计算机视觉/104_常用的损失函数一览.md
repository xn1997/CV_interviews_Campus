## CE loss（交叉熵、softmax损失）

二分类（sigmoid）下（也称为BCE loss，二分类交叉损失熵）：
$$
C E=\left\{\begin{array}{rll}
-\log (p), & \text { if } & y=1 \\
-\log (1-p), & \text { if } & y=0
\end{array}\right.
$$
多分类（softmax）下（也叫softmax loss）：
$$
C E=\left\{\begin{array}{rll}
-\log (p), & \text { if } & y=c \\
0, & \text { if } & y \neq c
\end{array}\right.
$$
y：输入此时对应的标签（不是真实值，其是任意一类）

p：输出在该目标类下的置信度

c：输入此时对应的真实标签

> sigmoid:
> $$
> \sigma(x)=\frac{1}{1+e^{-x}}=\frac{e^{x}}{1+e^{x}}
> $$
> 各结果之间独立，结果只和不一定为1
>
> 二分类的loss，必须同时提高正样本和负样本的判断准确率才行
>
> softmax:
> $$
> a_{i}=\frac{e^{z_{i}}}{\sum_{k} e^{z_{k}}}
> $$
> 各结果之间结果有联系，一个增加，其他的必定减小，结果和为1.
>
> **多分类的loss可以不用考虑负样本，只考虑将正样本的判断准确率提高即可，判断为负样本的置信度会自动减少。**

![image-20210723152245771](https://raw.githubusercontent.com/xn1997/picgo/master/image-20210723152245771.png)

## focal loss

解决**分类问题中类别不平衡、分类难度差异**的一个loss

**==正负样本数量不平衡的解决方法==**
$$
C E=\left\{\begin{aligned}
-\alpha \log (p), & \text { if } & y=1 \\
-(1-\alpha) \log (1-p), & \text { if } & y=0
\end{aligned}\right.
$$
添加$\alpha$，迫使数量较小的正样本在拥有更大的权值，在更新参数时拥有更大的权重，防止被数量巨大的负样本淹没。

**==难易样本数量不平衡的解决方法==**

作者认为，**易分样本（即，置信度高的样本）对模型的提升效果非常小，模型应该主要关注与那些难分样本**（**这个假设是有问题的，是GHM的主要改进对象**）
$$
F L=\left\{\begin{aligned}
-(1-p)^{\gamma} \log (p), & \text { if } \quad y=1 \\
-p^{\gamma} \log (1-p), & \text { if } \quad y=0
\end{aligned}\right.
$$
通过以上方法，**把高置信度（p）样本的损失降低**，这样损失就会更加关注低置信度的难分样本了。

**==即解决正负样本数目不平衡的问题，又解决难易样本数目不平衡==**

将上述两个方案结合就是最终的focal loss
$$
F L=\left\{\begin{aligned}
-\alpha(1-p)^{\gamma} \log (p), & \text { if } & y=1 \\
-(1-\alpha) p^{\gamma} \log (1-p), & \text { if } & y=0
\end{aligned}\right.
$$
实验表明$\gamma$取2,$\alpha$ 取0.25的时候效果最佳。这样训练过程关注对象的排序为正难>负难>正易>负易。

**多分类下**：
$$
F L=\left\{\begin{aligned}
-\alpha(1-p)^{\gamma} \log (p), & \text { if } & y=c \\
0, & \text { if } & y \neq c
\end{aligned}\right.
$$
比如易样本远比难样本多的话，模型肯定会倾向于数目多的易分样本（可以想象全部样本都判为易类），这时候，易分样本的$(1-p)^{\gamma}$很小，而难分样本的权值$p^{\gamma}$就很大，这时候模型就会开始集中精力关注难分样本。

### $\gamma$的作用

用于决定对易分样本的衰减程度，**越大**代表对易分样本的衰减程度越高，即**网络更加关注难分样本**。

当**$\gamma=0$​​​​**时，就**变成**了带有正负样本平衡的**普通CE loss**。

### 为什么$\alpha$​取0.25？

$\alpha$是为了平衡正负样本的数量，一般样本越多的类，$\alpha$越低。
在目标检测中，$\alpha$在正样本前，用于平衡正负样本loss比例，所以单独使用$\alpha$​时一般会大于0.5，论文中设置的是0.75时效果最好，这样就会**增加正样本对损失的贡献**。

但是focal loss中$\alpha$为0.25，小于0.5，这就意味着事实上正样本比负样本多，为什么呢？因为**使用focal loss之后，很多易分负样本权重被降的很低，继而导致难分正样本比难分负样本数量多，所以$\alpha$​小于0.5**。



### 参考链接

[5分钟理解Focal Loss与GHM——解决样本不平衡利器](https://zhuanlan.zhihu.com/p/80594704)

[【论文解读】Focal Loss公式、导数、作用详解](https://zhuanlan.zhihu.com/p/122542747)——为什么$\alpha$取0.25？

## smooth L1 loss

==L2 loss（注意不是smooth L2）==：均方差损失（MSE）。具体参考《57_机器学习中常用的损失函数一览.md》
$$
\text { Smooth } L_{1}=\left\{\begin{array}{l}
0.5 x^{2}, \quad|x|<1 \\
|x|-0.5, \quad \text{otherwise}
\end{array}\right.
$$
优点：（1）相比于L2损失函数，其对离群点（指的是距离中心较远的点）、异常值（outlier）不敏感，当异常值出现时，不至于产生特别大的梯度，造成梯度爆炸。（2）相比于L1损失函数，解是稳定的，对于L1，数据的一个微小移动就很可能导致参数跳过最优解，无法收敛到最优。==梯度不至于过大，且梯度可以足够小==

# 目标检测

**坐标GT经过原图的宽高进行了归一化**（0~1）

## 坐标回归+分类损失（写的不好）

以feature map上一个位置输出一个anchor为例

head输出：4个Bbox相关的变量 ![[公式]](https://www.zhihu.com/equation?tex=t_%7Bx%7D%2Ct_%7By%7D%2Ct_%7Bw%7D%2Ct_%7Bh%7D)，1个置信度损失（用于确定该处有目标的概率)

计算损失之前需要先根据输入计算出Bbox的真实位置，计算方法为：
$$
\left\{\begin{aligned}
b_{x} &=\sigma\left(t_{x}\right)+c_{x} \\
b_{y} &=\sigma\left(t_{y}\right)+c_{y} \\
b_{w} &=p_{w} e^{t_{w}} \\
b_{h} &=p_{h} e^{t_{h}} \\
\sigma\left(t_{o}\right) &=\operatorname{Pr}(\text { object }) \times \operatorname{IOU}(b, \text { object })
\end{aligned}\right.
$$
该位置在特征图左上角的偏移 ![[公式]](https://www.zhihu.com/equation?tex=%28c_%7Bx%7D%2Cc_%7By%7D%29)，预设的anchor box的宽和高 ![[公式]](https://www.zhihu.com/equation?tex=p_%7Bw%7D%2Cp_%7Bh%7D)，sigmoid函数（为了确保输出在0~1之间，防止目标框超出设定位置)，$\sigma (t_o)$指置信度预测值，是当前框有目标的概率乘以IOU的结果

在YOLOv3中，Loss分为三个部分:

- 一个是xywh部分带来的**坐标误差**，也就是bbox带来的loss
- 一个是**置信度**带来的误差，也就是obj带来的loss
- 最后一个是类别带来的**分类误差**，也就是class带来的loss

在代码中分别对应lbox, lobj, lcls，yolov3中使用的loss公式如下
$$
\begin{aligned}
\text { lbox }&=\lambda_{\text {coord }} \sum_{i=0}^{S^{2}} \sum_{j=0}^{B} 1_{i, j}^{o b j}\left(2-w_{i} \times h_{i}\right)\left[\left(x_{i}-\hat{x}_{i}\right)^{2}+\left(y_{i}-\hat{y}_{i}\right)^{2}+\left(w_{i}-\hat{w}_{i}\right)^{2}+\left(h_{i}-\hat{h}_{i}\right)^{2}\right] \\
\operatorname{lobj} &=\lambda_{\text {noobj }} \sum_{i=0}^{S^{2}} \sum_{j=0}^{B} 1_{i, j}^{\text {noobj }}\left(c_{i}-\hat{c_{i}}\right)^{2}+\lambda_{\text {obj }} \sum_{i=0}^{S^{2}} \sum_{j=0}^{B} 1_{i, j}^{o b j}\left(c_{i}-\hat{c}_{i}\right)^{2} \\
\text { lcls }&=\lambda_{\text {class }} \sum_{i=0}^{S^{2}} \sum_{j=0}^{B} 1_{i, j}^{o b j} \sum_{c \in \text { classes }} p_{i}(c) \log \left(\hat{p}_{i}(c)\right) \\
\text { loss }&=l b o x+lob j+l c l s
\end{aligned}
$$

### YOLOv1损失函数

<img src="https://raw.githubusercontent.com/xn1997/picgo/master/v2-aad10d0978fe7bc62704a767eabd0b54_720w.jpg" style="zoom:80%;" />

### YOLOv3 loss

<img src="https://img-blog.csdnimg.cn/20200622211901413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JibGluZ2JibGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

### YOLOv4 loss

<img src="https://img-blog.csdnimg.cn/20200628111323185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JibGluZ2JibGluZw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

### YOLOv5 Loss

使用的GIOU loss

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201201205124325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JibGluZ2JibGluZw==,size_16,color_FFFFFF,t_70)

### Faster RCNN

![img](https://img-blog.csdnimg.cn/20181108105638545.png)

分类损失：交叉熵——这里其实是softmax loss不是BCE loss

回归损失：smoothL1

参考链接：https://zhuanlan.zhihu.com/p/72579976

## 正负样本选择

loss计算中，“负责预测目标”（即正样本）和背景（即负样本），以及不参与计算loss的部分是怎么选择的：

### YOLOv3/v4

- **正样本的选择：**

首先计算目标中心点落在哪个grid上，然后计算这个grid的9个先验框（anchor）和目标真实位置的IOU值（直接计算，不考虑二者的中心位置），**取IOU值最大的先验框和目标匹配**。于是，找到的 该grid中的 该anchor 负责预测这个目标，其余的网格、anchor都不负责。

9个anchor指3个尺度、3个长宽比，由于使用了FPN所以，<u>三个特征层各负责一个尺度</u>。而在选择正负样本时，会<u>先计算GT与那个anchor的IOU最大，然后再判断该anchor是否属于当前特征图</u>，属于就是正样本。（即<u>这里的FPN与anchor的尺度是一一对应好的，知道哪个anchor负责这个GT，那么就知道哪个特征层负责这个GT了</u>）

- **不参与计算部分：**

**该anchor的预测结果和GT的IOU大于负样本阈值，切该anchor没有被归为是正样本的目标框**，这部分虽然不负责预测对象，但IOU较大，可以认为包含了目标的一部分，不可简单当作负样本，所以这部分不参与误差计算。

- **负样本的选择：**

不是正样本也不是忽略样本的其他anchor都记作负样本，其置信度应当为0。

综上，如下图所示：

<img src="https://img-blog.csdnimg.cn/2020052916485717.png" alt="在这里插入图片描述" style="zoom:50%;" />

#### 代码实现

**如何confidence loss**

就是使用的BCEloss，不过需要筛选出正样本和负样本，而最重要的就是如何筛选出正样本和负样本，这里是**借用了mask和noobj_mask来标记哪个anchor是正样本，哪个是负样本**。

以下程序注释必须记住，尤其是如何生成的mask和noobj_mask，及其01分别代表的含义，还有如何计算的置信度损失。

```python
        #   找到哪些先验框内部包含物体
        #   利用真实框和先验框计算交并比
        #   mask        batch_size, 3, in_h, in_w   有目标的特征点。1：有目标的特征点（作为正样本的anchor）；0：不参与正样本计算的anchor（负样本和忽略样本）
        #   noobj_mask  batch_size, 3, in_h, in_w   无目标的特征点。1：无目标的特征点（作为负样本的anchor）；0：不参与负样本计算的anchor（正样本和忽略样本）
        #                                                           忽略样本：一些anchor的预测结果和GT的IOU过大，不适合再作为负样本的非正样本。
        #                                                           1. 先选出与GT IOU最大的anchor作为正样本，生成mask。同时，将对应位置的noobj_mask置为1，表示该特征点不存在负样本
        #                                                           2. 再选出与GT IOU较大的预测结果的anchor作为忽略样本，即将这些目标踢出负样本，就是令noobj_mask置为0，变成忽略样本
        
        # 计算置信度的loss
         # 前者只计算正样本的置信度损失，后者只选出负样本的置信度损失（都是一次性计算出所有anchor的置信度损失，只不过利用mask从中抽出了对应的正样本和负样本损失
        loss_conf = torch.sum(BCELoss(conf, mask) * mask) + \
                    torch.sum(BCELoss(conf, mask) * noobj_mask)     
            
        # 返回每一个head有几个正样本参与训练，最后会据此对loss求平均，从而最终用于反向传播的loss是指平均一个正样本的loss值
        if self.normalize:
            num_pos = torch.sum(mask)
            num_pos = torch.max(num_pos, torch.ones_like(num_pos))
        else:
            num_pos = bs/3

        # loss：所有batch所有正样本的loss
        # num_pos：所有batch的所有正样本
        # 反向传播时会使用loss/num_pos对最终的loss进行归一化，再进行梯度计算
        return loss, num_pos            
```

### Faster RCNN

1. 为每个anchor匹配一个与其IOU最大的GT。（YOLO是为每个GT匹配一个IOU最大的anchor）
2. 将与GT IOU小于0.3的标记为负样本，大于0.7的标记为正样本，其余均作为忽略样本。
3. 为每个GT匹配一个与其IOU最大的anchor。
   同时将1中anchor对应的GT更新为2中的匹配结果，保证每个GT都有anchor可以匹配成功。
4. 然后从负样本随机选择，使得总样本数达到256。

### SSD

1. 同YOLO
   选择与GT IOU最大的anchor作为正样本。（此时正负样本很不平衡）
2. 对于剩余未匹配anchor，将与GT IOU超过0.5的作为正样本。这样一个GT就可以匹配多个anchor，增加正样本的数量。（此时负样本依然多于正样本）
3. hard negative mining，难负样本挖掘。将所有负样本**按照预测的背景置信度进行降序排序（预测背景的置信度越小，误差越大）**，选择误差大的前几个作为负样本，以保证正负样本比例接近1:3。

### YOLOv5

1. 将GT和当前层的3个anchor计算**宽高比**，并判断其中最大的比例是否在0.25~4之间，在该尺度anchor就是正样本，否则就认为比例差距过大是负样本。
2. 然后计算GT中心落在哪个网格，同时**利用四舍五入原则找出最近的两个网络**，这三个网格都负责预测该GT，从而相比原来YOLO的正样本扩充了3~9倍。
   GT可以在三个尺度下都匹配到anchor；负责预测GT的grid有三个。

样本扩充的依据是判断gt的中心点落在的网格相对的上下左右偏移量.( 例如,gt的中心在网格中偏向左上角,那么gt所在gird的上方和左方的gird也会被扩充为gt样本.同时,扩充的gird所对应的gt框是由原始的gt框移动一个单位到其所在的gird中) ,下面这张图可以很好的解释这一过程

<img src="https://img-blog.csdnimg.cn/20210427192758813.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTQ4MzkwNg==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述" style="zoom: 33%;" />

目标中心点为图中的红色点，红色点在本网格的左上，则让本网格、其左、其上网格负责该目标检测；
同理目标中心点如果在右下，则让本网格、其右、其下网格负责该目标检测。为什么这样做，据说是为了扩充正样本。

这种做法可以**使yolov5的gt框数量增加,很好的缓解了正负样本的不平衡**.然而这种通过将gt移动的方法进行扩充正样本,我觉得对于小目标来说,是存在很多的问题的

[Yolov5系列(3)-loss解析](https://blog.csdn.net/weixin_45483906/article/details/116204677)

### CenterNet

GT中心点落入的位置是正样本，其余都是负样本。

使用Focal loss平衡正负样本。

### FCOS

将落在GT内的所有anchor都视为正样本。
（产生很多靠近边缘的低质量anchor，所以增加centerness分支来衡量当前anchor靠近GT中心的尺度）

1. 确定GT应该由哪个特征层负责。
   <u>对于第一个特征图上的点，如果该点落在了GT内，而且满足**0 < max(中心点到4条边的距离) < 64**，那么该gt bbox就属于第1层负责</u>，其余层也是采用类似原则。总结来说就是第1层负责预测尺度在`0~64`范围内的gt，第2层负责预测尺度在`64~128`范围内的gt，其余类推。通过该分配策略就可以将不同大小的gt分配到最合适的预测层进行学习。
2. 落在GT范围内的所有点都是正样本。
   如果<u>一个点落入多个GT内</u>，那么就让该点<u>负责较小面积的GT</u>。

## 参考链接

[【从零开始学习YOLOv3】8. YOLOv3中Loss部分计算](https://www.cnblogs.com/pprp/p/12590801.html)

# 骨架检测

假设关节点个数为V

## Detection loss（heatmap loss）

关节点位置损失

head输入：V个heatmap，一个heatmap代表一类关节点，heatmap的值为该位置为关节点的概率。

1. 对GT使用高斯模糊，得到用于计算loss的GT。高斯模糊是为了可以平滑的学习关节点位置，不平滑那么就很难学习出关节点位置，因为他不知道应该学习的趋势。（个人理解）
2. 将heatmap与GT逐像素求均方误差。（这里和语义分割的loss一致）

## Grouping loss

分组损失

head输出：同关节点位置损失，V个heatmap，一个heatmap代表一类关节点，heatmap的值为该位置对应关节点的标签（tag）值。

1. 根据GT找出所有关节点对应的tag值。
2. 求出每个人所有关节点tag值的均值。
3. 同一个人所有关节点tag值与其均值的均方差+不同人tag均值之间的高斯下降函数=Grouping loss

<img src="https://www.zhihu.com/equation?tex=L_g%28h%2CT%29%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bn%7D%5E%7B%7D%7B%7D%5Csum_%7Bk%7D%5E%7B%7D%7B%28%5Cbar%7Bh%7D_n-h_k%28x_%7Bnk%7D%2C%29%29%5E2%7D%2B%5Cfrac%7B1%7D%7BN%5E2%7D%5Csum_%7Bn%7D%5E%7B%7D%7B%7D%5Csum_%7Bn%27%7D%5E%7B%7D%7Bexp%5C%7B-%5Cfrac%7B1%7D%7B2%5Csigma%5E2%7D+%28%5Cbar%7Bh%7D_n-%5Cbar%7Bh%7D_%7Bn%27%7D%29%5E2%5C%7D+%7D%5C%5C" alt="[公式]" style="zoom:80%;" />

 最小化该loss可以**使得个体内每个关节tag图的embedding值趋于一致，不同个体的embedding相差较远**，实现分组。

**注意：tag的embedding并非事先固定好的标签，只要一个个体内的embedding一致即可，也就是说，每个个体对应的embedding是学习出来的**

总损失
$$
L=0.001L_g+0.999L_d
$$

## PAF（Part Affinity Fields）

分组损失

head输出：2*(V+1)个heatmap（这里称为vectormap），2个heatmap代表了一个骨骼的位置和方向（也就是两个关节点位置之差，2指方向向量的xy维度）

**注意：实际情况下，增加了耳朵和肩膀的骨骼，以方便预测耳朵，因为耳朵容易被遮挡，所以vectormap的通道为2*(V+1)**

1. 生成vectormap的GT。

   1. 计算骨骼的单位方向向量，也就是求两个关节点坐标间的方向向量v。

   2. 设置一个骨骼宽度，将该骨骼范围内（矩形区域）的所有像素都设置为方向向量v。（这个计算比较复杂，但大致意思是这样，思路简单）

      <img src="https://math.jianshu.com/math?formula=L_%7Bc%2Ck%7D%5E*(p)%3D%5Cbegin%7Bcases%7D%20v%2C%20%5Cquad%20if%20%5C%20p%20%5C%20on%5C%20limb%5C%20c%5C%20%2Ck%20%5C%5C%5C%5C%200%2C%20%5Cquad%20otherwise%20%5Cend%7Bcases%7D" alt="L_{c,k}^*(p)=\begin{cases} v, \quad if \ p \ on\ limb\ c\ ,k \\\\ 0, \quad otherwise \end{cases}" style="zoom:70%;" />

   <img src="https://math.jianshu.com/math?formula=v%3D%5Cfrac%7B(x_%7Bj2%2Ck%7D-x_%7Bj1%2Ck%7D)%7D%7B%7C%7Cx_%7Bj2%2Ck%7D-x_%7Bj1%2Ck%7D%7C%7C_2%7D" alt="v=\frac{(x_{j2,k}-x_{j1,k})}{||x_{j2,k}-x_{j1,k}||_2}" style="zoom:80%;" />

2. 同Detection loss，直接求预测和GT的vectormap的逐像素均方误差，即可作为loss

关节关联：计算关节点之间方向向量积分，并作为二者的边权值，利用匈牙利匹配找出同一个人的所有关节点。

# 参考

[论文笔记-Associative Embedding](https://zhuanlan.zhihu.com/p/45187349)（Detection+Grouping loss）

[人体姿态估计--OpenPose算法解析](https://www.jianshu.com/p/98c11545d4fb)（PAF，介绍的很好，细节很详细）
## 问题

深度学习中有很多优化函数，常见的那些你还记得它的定义以及优缺点吗？

## 背景知识

深度学习网络训练中，有很多可供选择的优化函数如SGD、Adam等等，到底用哪个好呢？其实这个问题没有确切的答案，优化函数是需要配合损失函数使用的，说白了，优化函数也是一种超参数，是需要尝试的，哪个效果好就用哪个……

这些优化函数其实差别不大，都是基于一个基本框架来演进的，所以下面先介绍下优化算法的基本框架：

### １、优化算法基本框架

（记住这个框架！！！）

假设当前时刻待优化的参数为 $\theta_t$ ，损失函数为 $J(\theta)$ ，学习率为 $\eta$ ，参数更新的框架为：

1. 计算损失函数关于当前参数的梯度：$g_t = \nabla J(\theta_t)$

2. 根据历史梯度计算一阶动量和二阶动量：
   $$
   m_t = \phi(g_1, g_2, ...,g_t)\\
   V_t = \psi(g_1,g_2,...,g_t)
   $$
   即一阶动量为包含当前梯度在内的历史梯度的一次函数，而二阶动量是历史梯度的二次函数。

3. 计算当前时刻的下降梯度：
   $$
   \Delta \theta_t = -\eta*\frac{m_t}{\sqrt{V_t}}
   $$

4. 根据下降梯度更新参数：$\theta_{t+1} = \theta_t + \Delta \theta_t$

### ２、指数加权移动平均值

SGD只计算当前梯度更新参数，完全没有考虑历史梯度，但这样有一个问题是假如当前参数处在损失函数的局部最低点处，即梯度为0，因为梯度为0，所以参数不再更新，也就是说不管你之前历史梯度多大，下降地多快，只要你当前梯度为0，那就只能停在这里，也就意味着冲不出这个局部最低点。要解决这个问题就需要将历史梯度考虑进来，但是这里又有一个问题：历史梯度那么多，全部都考虑吗，还是只考虑一部分？其实我们只要考虑最近的一段历史梯度即可，这段历史梯度怎么截就用到了**指数加权移动平均值**的概念。

假设 $\upsilon_{t-1}$ 是 $t-1$ 时刻的指数加权移动平均值，$\theta_t$ 是当前 $t$ 时刻的观测值，那么 $t$ 时刻的指数加权移动平均值为：
$$
\upsilon_t = \beta \upsilon_{t-1} + ( 1- \beta)\theta_t \\
\quad= ( 1- \beta)\theta_t + ( 1- \beta)\beta\theta_{t-1}+ \beta^2\upsilon_{t-2}\\
\quad= ( 1- \beta)\theta_t + ( 1- \beta)\beta\theta_{t-1}+ ( 1- \beta)\beta^2\theta_{t-2}+ \beta^3\upsilon_{t-3} \\
...(递推)\\
 = (1-\beta)\theta_t + \sum_{i=1}^{t-1}(1-\beta)\beta^i \theta_{t-i}
$$
其中 $0 \leq \beta \le 1$ ，从指数加权移动平均值的最终形式可以看出，$i$ 表示的是距离当前时刻的时间长短，$i$ 越大代表着距离当前时刻越久远，且由于其系数中指数部分的影响，其系数越小，也就是说距离当前时刻越远的历史梯度对当前时刻的指数加权移动平均值的贡献越少，这时候若我们设置一个阈值来对贡献量进行筛选，便使得当前时刻的指数加权移动平均值只考虑距离当前时刻较近的那些历史梯度，这就对应了名字中的“移动”这个概念。

除了第 $t$ 时刻的观测值权重为 $1-\beta$ 外，其他时刻的观测值权重为 $(1-\beta)\beta^i$ 。由于通常对于那些权重小于 $\frac{1}{e}$ 的观测值可以忽略不计，所以忽略掉那些权重小于这个阈值的观测值之后，上式就可以看做是在求指数加权**移动**平均值。

 下面我们计算一下什么时候权重 $(1-\beta)\beta^i$ 等于$\frac{1}{e}$ 的。

高数中有一个重要极限公式：
$$
\qquad \qquad\qquad\qquad\qquad\qquad\lim_{n \rightarrow \infty}(1+\frac{1}{n})^n= e \\
其实这个极限无论是对于+\infty还是-\infty都是成立的，因此我们令 t=-n，得:\\
lim_{t \rightarrow -\infty} (1-\frac{1}{t})^{-t} = e\quad \rightarrow \quad lim_{n \rightarrow \infty} (1-\frac{1}{n})^{n} = \frac{1}{e} \approx 0.3679 \\
令 n=\frac{1}{1-\beta}，则: \\
lim_{n \rightarrow \infty} (1-\frac{1}{n})^{n} = lim_{\beta \rightarrow 1}(\beta)^{\frac{1}{1-\beta}} = \frac{1}{e}
$$ {l}
所以当 $\beta \rightarrow1$ 时，那些 $i \ge \frac{1}{1-\beta}$ 的 $\theta_{t-i}$ 的权重 $(1-\beta)\beta^i$ 的权重肯定小于 $\frac{1}{e}$ 。**$\beta$ 通常取0.9，也就是说 $i \ge 10$ 的那些观测值都会被忽略，也就相当于只考虑包括当前时刻在内的最近10个时刻的指数加权移动平均值。**

但是还有一个问题是：当 t 比较小时，指数加权移动平均值的偏差较大，例如：设 $\theta_1=40,\beta=0.9$ ，那么 $v_1 = \beta v_0 + (1-\beta)\theta_1 = 0.9*0+0.1*40 = 4$ ，显然 $v_1$ 和 $\theta_1$ 相差太大，所以通常会加上一个修正因子 $1-\beta^t$ ，加上修正因子后的公式为：
$$
\upsilon_t = \frac{\beta \upsilon_{t-1} + ( 1- \beta)\theta_t}{1-\beta^t} \\
$$
显然，当 t 较小时，修正因子  $1-\beta^t$ 会起作用，当 t 足够大后，$\beta^t \rightarrow 0, (1-\beta^t) \rightarrow 1$ ，修正因子自动退场。**加修正因子的这个做法只有在 Adam 和 Nadam 中使用到，其他算法并没有考虑。**

## SGD (Stochastic Gradient Descent)

SGD不考虑历史梯度，所以当前时刻的一阶动量即为当前时刻的梯度 $m_t = g_t$ ，且二阶动量 $V_t = E$ ，所以SGD的参数更新公式为：
$$
\Delta \theta_t = -\eta*\frac{g_t}{\sqrt{E}} = -\eta*g_t \\
\theta_{t+1}= \theta_t + \Delta\theta_t = \theta_t-\eta*g_t
$$
**缺点**：容易陷入局部最优。由于SGD只考虑当前时刻的梯度，在局部最优点的当前时刻梯度为 0 ，根据上面计算公式可知，此时参数不再进行更新，故陷入局部最优的状态。

但是虽然SGD有陷入局部最优的缺陷，但还是很常用。我的理解是：以上分析是针对一个参数 $\theta_i$ 来说的，即使其中一个参数陷入局部最优，但其他参数还是会继续更新，所以大概率会将陷入局部最优的那个参数拖离局部最优点，于是该参数可以继续更新。 所以整体来说并不会像单个参数那样陷入局部最优就出不来，所以还是可以work的。

### 改进策略及算法

1. **引入历史梯度的一阶动量**，代表算法：Momentum、NAG
2. **引入历史梯度的二阶动量**，代表算法：AdaGrad、RMSProp、AdaDelta
3. **同时引入历史梯度的一阶动量及二阶动量**，代表算法：Adam、Nadam

## Momentum

为了抑制SGD的震荡（有点不理解这句话），Momentum认为梯度下降过程可以加入惯性，也就是在SGD的基础上引入了一阶动量。而所谓的一阶动量就是该时刻梯度的指数加权移动平均值，而由于此时仍然没有用到二阶动量，所以 $V_t=E$ ，所以Momentum的参数更新公式如下：
$$
m_t = \beta m_{t-1}+\eta g_t \\
\Delta\theta_t = -\eta*\frac{m_t}{\sqrt{E}} = -\eta*m_t = -(\beta m_{t-1}+\eta g_t) \\(这里m_t乘以\eta后可以视为不变，因为乘上后，系数同样是大于0小于1的) \\
\theta_{t+1} = \theta_t -(\beta m_{t-1}+\eta g_t)
$$
可以看到上面式子的**第一行 $g_t$ 前面的系数并不是严格按照我们上面指数加权移动平均值的定义采用权重 $1-\beta$ ，而是使用我们自定义的学习率 $\eta$ **，这点需要注意。 

## NAG (Nesterov Accelerated Gradient)

除了利用惯性（一阶动量）跳出局部沟壑外，我们还可以尝试往前看一步，即：在Momentum考虑历史梯度的基础上，把当前梯度转换为未来梯度。

想象一下你走到一个盆地，四周都是略高的小山，你觉得没有下坡的方向，那就只能待在这里了。可是如果你爬上高地，就会发现外面的世界还很广阔。因此，我们不能停留在当前位置去观察未来的方向，而要向前多看一步。我们知道Momentum在时刻 $t$ 的主要下降方向是由历史梯度（惯性）决定的，当前时刻的梯度权重较小，那不如不用管当前梯度，而是先看看如果跟着惯性走了一步，那个时候外面的世界是怎样的。也即在Momentum的基础上将当前时刻的梯度换成下一时刻的梯度。由于此时仍然没有用到二阶动量，所以 $V_t=E$ ，所以NAG的参数更新公式为：
$$
Momentum中原本下一个时刻的梯度计算公式为:\theta_{t+1} = \theta_t -(\beta m_{t-1}+\eta g_t) \\
不考虑当前梯度即令;g_t = 0 \\ 
所以下一个时刻的梯度的计算公式为：　\theta_{t+1} = \theta_t -\beta m_{t-1} \\
所以将当前时刻的梯度换成下一时刻的梯度即:g_t = \Delta J(\theta_t -\beta m_{t-1})\\
上式代入到Momentum的参数更新公式中：\theta_{t+1} = \theta_t -(\beta m_{t-1}+\eta \Delta J(\theta_t -\beta m_{t-1}))
$$

___

> 以上的两个概念只引入了一阶动量。而二阶动量的出现，才意味着**“自适应学习率”**优化算法时代的到来。在SGD及其引入一阶动量的改进算法中，均以相同的学习率去更新参数。但是，以相同的学习率进行变化经常是不合理的。
>
> 在神经网络中，参数需要用不同的学习率进行更新。<font color='red'>对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于那些偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。</font>
>
> 以神经网络中的 W 及 b 为例，如下图为损失函数等高线图，W 为横轴，b 为纵轴。发现每次b 变化很大，而 W 每次仅更新一小步。但是，纵观整个损失函数我们发现，W 其实可以迈开步子往前走，而 b 则不用那么活跃。
>
> ![img](https://i.loli.net/2020/05/14/KXrhZpb4CSTYJRz.jpg)
>
> 于是，出现了以下针对不同维度的参数采用不同学习率的二阶动量改进算法。

## AdaGrad

从数学的角度来看，更新幅度很大的参数，通常其历史累计梯度的平方和会很大；相反，更新幅度很小的参数，通常其累计历史梯度的平方和会很小。因此，我们可以考虑让学习率除以历史梯度的平方和，这样之前更新幅度大的参数的学习率分母也大，之前更新幅度小的参数的学习率分母也小，从而起到调节学习率的效果。

我们上面讨论的 $\theta_t$ 指的是网络中的参数，但是参数有很多个，所以其实 $\theta_t$ 是一个向量，我们假设网络中有 d 个参数，那么 $\theta_t = [\theta_{t,1}, \theta_{t,2},..\theta_{t,d}]^T$ 。那么针对其中的第 i 维度的参数梯度更新公式为：
$$
\upsilon_{t,i} = \sum_{t=1}^{t}g_{t,i}^2 \\
\Delta \theta_{t,i} = -\frac{\eta}{\sqrt{\upsilon_{t,i}+\varepsilon}}*g_{t,i} \\ \theta_{t+1, i}=\theta_{t,i}-\frac{\eta}{\sqrt{\upsilon_{t,i}+\varepsilon}}*g_{t,i}
$$
其中 $g_{t,i}$ 表示第 t 时刻第 i 维度参数的梯度值，$\varepsilon$ 是防止分母等于 0 的平滑项（常取一个很小的值例如 1e-8） 。显然，此时上式中的 $-\frac{\eta}{\sqrt{\upsilon_{t,i}+\varepsilon}}$ 这个整体可以看作是学习率，分母中的历史累计梯度值 $v_{t,i}$ 越大的参数学习率越小。

上式仅仅是第 t 时刻第 i 维度参数的更新公式，对于第 t 时刻所有维度的参数的更新公式如下：
$$
V_t = diag(\upsilon_{t,1}, \upsilon_{t,2},...,v_{t,d}) \in R^{d*d} \\
\Delta \theta_{t} = -\frac{\eta}{\sqrt{V_t+\varepsilon}}*g_{t} \\
\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{V_t+\varepsilon}}*g_{t}
$$
也就是构造成矩阵相乘的形式：　$V_t$ 是对角矩阵（除了对角线有非零值外其他地方都是 0 ） 所以上式中的 $\varepsilon$ 只用来平滑 $V_t$ 对角线上的元素。

**缺点**：随着时间步的拉长，历史累计梯度平方和 $v_{t,i}$ 会越来越大，这样会使得所有维度参数的学习率都不断减小（单调递减），无论更新幅度如何。

## RMSProp / AdaDelta

由于 AdaGrad 单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累计全部历史梯度，而只关注过去一段时间窗口的下降梯度，采用 Momentum 中的指数加权移动平均值的思路。

首先看最简单直接版的 **RMAProp** ，RMSProp 就是在 AdaGrad 的基础上将普通的历史累计梯度平方和换成历史累计梯度平方和的指数加权移动平均值，所以只需将 AdaGrad 中的 $v_{t,i}$ 的公式改成指数加权移动平均值的形式即可：
$$
v_{t,i} = \beta v_{t-1,i} + (1-\beta)g_{t,i}^2 \\
V_t = diag(\upsilon_{t,1}, \upsilon_{t,2},...,v_{t,d}) \in R^{d*d} \\
\Delta \theta_{t} = -\frac{\eta}{\sqrt{V_t+\varepsilon}}*g_{t} \\
\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{V_t+\varepsilon}}*g_{t}
$$
而 **AdaDelta** 又在 RMSProp 的基础上进行改进：它除了对二阶动量计算指数加权移动平均值之外，还对学习率动了手脚，即要达到的目标是不需要我们人为设定固定的学习率，而是让模型根据历史经验将学习率给换掉。所以另外它会对当前时刻的下降梯度 $\Delta \theta_t$ 的平方也计算一个指数加权移动平均，具体的：
$$
E[\Delta \theta^2]_{t,i} = \gamma E[\Delta \theta^2]_{t-1,i} + (1-\gamma)\Delta \theta_{t,i}^2
$$
由于 $\Delta \theta_{t,i}^2$ 目前是未知的，所以只能用 t-1 时刻的指数加权移动平均值来近似替换，也即：
$$
E[\Delta \theta^2]_{t-1,i} = \gamma E[\Delta \theta^2]_{t-2,i} + (1-\gamma)\Delta \theta_{t-1,i}^2
$$
接着 AdaDelta 将此值替换我们预先设置的学习率 $\eta$ 。

因此，AdaDelta 的参数更新公式如下：
$$
v_{t,i} = \beta v_{t-1,i} + (1-\beta)g_{t,i}^2 \\
V_t = diag(\upsilon_{t,1}, \upsilon_{t,2},...,v_{t,d}) \in R^{d*d} \\
E[\Delta \theta^2]_{t-1,i} = \gamma E[\Delta \theta^2]_{t-2,i} + (1-\gamma)\Delta \theta_{t-1,i}^2 \\
\Theta_t = diag(E[\Delta \theta^2]_{t-1,1}, E[\Delta \theta^2]_{t-1,2}, ...,E[\Delta \theta^2]_{t-1,d}) \in R^{d*d}\\
\Delta \theta_{t} = -\frac{\sqrt{\Theta_t + \varepsilon}}{\sqrt{V_t+\varepsilon}}*g_{t} \\
\theta_{t+1}=\theta_{t}-\frac{\sqrt{\Theta_t + \varepsilon}}{\sqrt{V_t+\varepsilon}}*g_{t}
$$
显然，对于 AdaDelta 算法来说，已经不需要我们自己预设学习率了，只需要预设 $\beta$ 和 $\gamma$ 这两个指数加权移动平均值的衰减率即可。

___

> 下面的两个算法对SGD的改进策略是同时引入一阶动量和二阶动量。Adam和Nadam都是前述方法的集大成者。

## Adam

在 RMSProp 的基础上再考虑一阶动量(Momentum)。具体如下：

首先计算一阶动量：（注意这个公式中 $g_t$ 前面的系数与Momentum是不同的）
$$
m_t = \beta_1 m_{t-1}+(1-\beta_1)g_t
$$
然后类似 RMSProp 和 AdaDelta 计算二阶动量：
$$
v_{t,i} = \beta_2 v_{t-1,i} + (1-\beta_2)g_{t,i}^2 \\
V_t = diag(\upsilon_{t,1}, \upsilon_{t,2},...,v_{t,d}) \in R^{d*d} \\
$$
**但是这里要加上修正因子**，即：（如果忘了这个回到前面去再看看指数加权移动平均值概念的最后部分）
$$
\hat{m}_t = \frac{m_t}{1-\beta_1^t} \\
\hat{v}_{t,i} = \frac{v_{t,i}}{1-\beta_2^t} \\
\hat{V}_t = diag(\hat{v}_{t,1}, \hat{v}_{t,2},...,\hat{v}_{t,d}) \in R^{d*d} \\
$$
所以，Adam的参数更新公式为：
$$
\Delta \theta_{t} = -\frac{\eta}{\sqrt{\hat{V}_t+\varepsilon}}*\hat{m}_{t} \\
\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{\hat{V}_t+\varepsilon}}*\hat{m}_{t}
$$

## Nadam

从这名字也能看出，Nadam = Nestrov + Adam ，具体思想如下：由于 Nesterov 的核心在于，计算当前时刻的梯度 $g_t$ 时使用了 "未来梯度" $\Delta J(\theta_t - \beta m_{t-1})$ ，Nadam 基于此提出了一种公式变形的思路，大意可以这样理解：只要能在梯度计算中考虑到 "未来梯度" ，就算达到了 Nestrov 的效果。既然如此，我们不一定非要在计算 $g_t$ 时使用 "未来梯度" ，可以考虑在其他地方使用未来梯度。

具体的，首先在 Adam 的基础上将 $\hat{m_t}$ 展开：
$$
\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{\hat{V}_t+\varepsilon}}*\hat{m}_{t}\\
=\theta_{t}-\frac{\eta}{\sqrt{\hat{V}_t+\varepsilon}}*(\frac{\beta m_{t-1}}{1-\beta_1^t}+\frac{(1-\beta_1)g_t}{1-\beta_1^t})
$$
此时，如果我们将第 t-1 时刻的动量 $m_{t-1}$ 用第 t 时刻的动量 $m_t$ 近似代替的话，那么我们就引入了 "未来因素" ，所以便可以得到 Nadam 的表达式为：
$$
\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{\hat{V}_t+\varepsilon}}*(\frac{\beta m_{t}}{1-\beta_1^t}+\frac{(1-\beta_1)g_t}{1-\beta_1^t})
$$

## 细节点

实际上学术界上对于SGD和Adam哪个更好，一直没有统一的定论，取决于实际项目情况。

优化函数**如果训练比较小的自定义的数据集，adam是比较合适的选择**，但是如果训练**大型的数据集那么使用sgd**优化函数的比较多。yolov4使用的就是sgd

### SGD和Adam的区别

Adam引入了一阶动量：SGD容易陷入局部最优，而一阶动量利用过去的信息，可以帮助冲出局部最优点。

Adam引入了二阶动量：实现了自适应学习率。对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于那些偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些，因此利用二阶信息就可以衡量每个参数的更新幅度。

#### Adam缺点

1. **可能不收敛**
   SGD没有用到二阶动量，因此学习率是恒定的（实际使用过程中会采用学习率衰减策略，因此学习率递减）。AdaGrad的二阶动量不断累积，单调递增，因此学习率是单调递减的。因此，这两类算法会使得学习率不断递减，最终收敛到0，模型也得以收敛。
   AdaDelta和Adam则不然。**二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得$V_t$​​​可能会时大时小，不是单调变化**。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。
2. **可能错过全局最优解**
   同样的一个优化问题，不同的优化算法可能会找到不同的答案，但自适应学习率的算法往往找到非常差的答案。**自适应学习率算法可能会对前期出现的特征过拟合，后期才出现的特征很难纠正前期的拟合效果**。

##### 参考链接

[（转）优化时该用SGD，还是用Adam？——绝对干货满满！](https://blog.csdn.net/S20144144/article/details/103417502)

### SGD的S(stochastic随机)体现在哪里

随机体现在，每一步的梯度都是通过**从全部数据中随机选择一个minbatch**来计算loss得到的，minbatch的loss和全部数据loss不一样，其是在不断的振动的，但最后是达到全局最优的。

#### 参考链接

[随机梯度下降算法中的随机性体现在哪里？如果已经可以保证随机性，为何还要在梯度中加入差分隐私？](https://www.zhihu.com/question/439932988)

### Adam和SGD切换时学习率应该怎样变化

Adam的学习率一般为0.001

前言：SWATS这篇论文详细介绍了当Adam切换为SGD时学习率应该如何变化，以下也是对该算法的解析。[点击下载论文](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.07628)

**目标：根据Adam的梯度下降方向求出SGD此时应该对应的学习率。**

<big><font color='blue'>学习率切换流程</font></big>

![img](https://pic4.zhimg.com/80/v2-958d364456bd8191096078b04f3748bf_720w.jpg)

蓝色部分就是Adam的计算方法（一模一样，没有任何不同，详情看Adam节）。**$p_k$​​就是Adam的梯度下降方向。$\gamma_k$​就是SGD的学习率。**

<big><font color='blue'>学习率切换推导</font></big>

由Adam和SGD的优化策略我们可以得出他们的下降方向分别为（和Adam和SGD节写的一样）

![[公式]](https://www.zhihu.com/equation?tex=%5Ceta_t%5E%7BAdam%7D+%3D+%28%5Calpha%2F+%5Csqrt%7BV_t%7D+%29+%5Ccdot+m_t)

![[公式]](https://www.zhihu.com/equation?tex=%5Ceta_t%5E%7BSGD%7D+%3D+%5Calpha%5E%7BSGD%7D%5Ccdot+g_t)

注意：伪代码和这里公式的对应关系为，这里的<u>Adam下降方向$\eta_t^{Adam}= p_k$​，SGD的学习率$\alpha^{SGD}=\gamma_k$​，梯度$g_t=g_k$​</u>。

因为Adam和SGD的下降方向都是向量，既然是向量，那么$\eta_t^{SGD}$必定可以分解为所$\eta_t^{Adam}$在方向及其正交方向上的两个方向之和，那么其**在$\eta_t^{Adam}$方向上的投影**就意味着**SGD在<u>Adam算法决定的下降方向</u>上前进的距离**，而**在$\eta_t^{Adam}$​​的正交方向上的投影**是 **SGD 在<u>自己选择的修正方向</u>上前进的距离**。如下图所示，不过下图的变量和伪代码的相同，注意和以上公式的对应关系即可。

<img src="https://img-blog.csdnimg.cn/20191206105806606.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1MyMDE0NDE0NA==,size_16,color_FFFFFF,t_70" alt="img" style="zoom:50%;" />

Adam可以切换为SGD的前提是：切换到SGD后，**SGD必须要走完Adam未走完的路**（就是$p_k$​那一段），而后再沿着其正交方向走相应的一步。<u>其实就是走图中红色虚线那一块</u>。

所以必须保证<big>**SGD在Adam下降方向上的正交投影，应该正好等于Adam的下降方向**</big>，也就是如下式子
$$
SGD在Adam下降方向上的正交投影=\frac{-\gamma_kg_k*p_k}{|p_k|}(根据向量的投影公式计算得到的) \\
建立等式：\frac{-\gamma_kg_k*p_k}{|p_k|}=|p_k| \\
即:\gamma_k=\frac{p_k^Tp_k}{-p_k^Tg_k} (就是伪代码中的式子)\\
替换为\eta_t^{Adam}，公式就变为了 \\
\alpha_t^{SGD}=\frac{(\eta_t^{Adam})^T\eta_t^{Adam}}{(\eta_t^{Adam})^Tg_t}
$$
以上就得出了Adam切换为SGD时，SGD学习率的变化公式，可以看出，学习率只和Adam的梯度方向及此刻的梯度有关。

为了减少噪声影响，作者<u>使用**移动平均值**来修正对学习率的估计</u>：

![[公式]](https://www.zhihu.com/equation?tex=%5Clambda_t%5E%7BSGD%7D%3D%5Cbeta_2%5Ccdot%5Clambda_%7Bt-1%7D%5E%7BSGD%7D+%2B+%281-%5Cbeta_2%29+%5Ccdot%5Calpha_t%5E%7BSGD%7D)

![[公式]](https://www.zhihu.com/equation?tex=%5Ctilde%7B%5Clambda%7D_t%5E%7BSGD%7D%3D%5Clambda_t%5E%7BSGD%7D%2F%281-%5Cbeta_2%5Et%29)

这里直接复用了Adam的$\beta_2$​​​参数。（上面的移动平均算法和Adam一模一样，第二个式子同样是为了添加修正因子）

<big><font color='blue'>何时进行算法的切换</font></big>

根据伪代码可以看出，当 SGD的相应学习率的移动平均值基本不变的时候，即：$|\tilde{\lambda}_t^{SGD} - \alpha_t^{SGD}|<\epsilon$​。每次迭代都计算一下SGD接班人的相应学习率，如果发现基本稳定了，那就SGD以为$\tilde{\lambda}_t^{SGD}$​学习率接班前进。

#### 参考链接

[（转）优化时该用SGD，还是用Adam？——绝对干货满满！](https://blog.csdn.net/S20144144/article/details/103417502)

## 参考资料

[１、深度学习中的优化算法串讲](https://mp.weixin.qq.com/s?__biz=MzI5MDUyMDIxNA==&mid=2247493857&idx=3&sn=34e8a373adee73f6bbe6dff740b7ede5&chksm=ec1c0518db6b8c0ef85381973446ab9ab215ccc07e4c7787a7b4e5dcb873ba5d81eec3ba164c&scene=0&xtrack=1#rd)
[２、以上资料的视频讲解](https://www.bilibili.com/video/av94067702/)

​																																												By Yee
​																																											2020.05.14
## GCN

- 拉普拉斯矩阵 = 图的度 - 邻接矩阵。参考链接：[拉普拉斯矩阵与拉普拉斯算子的关系](https://zhuanlan.zhihu.com/p/85287578)

  含义：每一行各元素的和为0，即度 = 其他相邻结点数目，假设度 = 3

  直观理解每一行：该处结点的能量**流出3**点，相邻三个结点各**流入1**点

  **图拉普拉斯**反映了当我们在节点`i`上施加一个势，这个势以**哪个**方向能够多**顺畅**的流向其他节点。

- 归一化

  使得每一行和为1，避免因为某个结点度过大

- **GCN中的卷积**

  参考链接：[何时能懂你的心——图卷积神经网络（GCN）](https://zhuanlan.zhihu.com/p/71200936)——侧重理解，并非推导

  [如何理解 Graph Convolutional Network（GCN）？](https://www.zhihu.com/question/54504471/answer/332657604)——清华博士的回答，纯数学，目前看不懂

  各层特征提取方法如下
  $$
  H^{(l+1)}=\sigma\left(\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} H^{(l)} W^{(l)}\right)
  $$

  1. $$\tilde{A}=A+I$$意义：邻接矩阵没有考虑自身结点特征，+单位矩阵以考虑自身结点

  2. $$\tilde{D}$$为$$\tilde{A}$$的度矩阵（不是A的）

     - $$\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$$用于归一化$$\tilde{A}$$，使得$$\tilde{A}$$每一行的和都为1，这样可以防止某个结点度过多，最后矩阵相乘时，***加权求和***的值过大，打乱结点数据的分布。

     - 使用$$\tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}}$$而不是$$\tilde{D}^{-1} \tilde{A}$$是参考了**对称归一化**拉普拉斯矩阵，可以让得到的矩阵**依然对称**。

## 高阶邻近矩阵的计算方法

**写在前面**

**$A^m$​的元素意义：如果元素非空就代表，m领域内这些点是可以连通的**。也有解释是指：点与点之间走m步能够到达的方案总数。

所以第一代的高阶矩阵直接使用高次幂表示，缺点就是各个位置的权值不同。

MS-G3D就是每一阶只考虑走m步可以刚好达到的位置，所以**具体的实现就是$(A^m>=1)-(A^{m-1}>=1)+I$**，这里和后面的理论结果是一样的。



目前我们使用的邻接矩阵的k次幂来求k阶邻居的计算方式如下：

![img](https://pic2.zhimg.com/80/v2-ed5e07905fbdfa63298b90f4e18851f5_720w.jpg)

我们以下面这个例子来进行观察，当我们以节点1分别来求1，2，3阶邻居时，我们会发现相对与k阶邻居来说，**距离节点1较近的和度比较大的颜色更深（权重更大）**,这就是作者说的**biased weighting problem。**

![img](https://pic3.zhimg.com/80/v2-d346492cf93920e3c1861b874961fdea_720w.jpg)

颜色越深表示权重越大

用pytorch计算了一下该矩阵，如下：

![img](https://pic1.zhimg.com/80/v2-b7bd59d4cd816043f9bf745d1120d7f8_720w.jpg)

从左到右分别是1阶邻接矩阵，2阶邻接矩阵，3阶邻接矩阵

为了解决**biased weighting problem，**设置新的邻接矩阵

<img src="https://pic1.zhimg.com/80/v2-efa9fdce9e70a11ad6cfc978a0396be8_720w.jpg" alt="img" style="zoom: 67%;" />

使用了递推的方式，首先设置好A1和A0

<img src="https://pic1.zhimg.com/80/v2-80ad448817ce52966b02dc6ac73f8ecc_720w.png" alt="img" style="zoom:67%;" />

然后使用做差来求高阶的邻接矩阵

<img src="https://pic2.zhimg.com/80/v2-0f8551b32fe53e3558cca658fc2a0e0d_720w.png" alt="img" style="zoom:67%;" />

I指的是自连接矩阵，后面1那部分表示的意思是:将邻接矩阵k次幂得到的矩阵中元素大于1的元素全都变为1

我们可以观察这种方式求k阶邻居的效果如下:我们可以看到除了k阶邻居和节点本身外，其他节点的权重都为0

![img](https://pic2.zhimg.com/80/v2-554d66a63ecf6a05e26680b304c65e51_720w.jpg)

下面是使用pytorch用作者提出的公式计算得到结果:

![img](https://pic2.zhimg.com/80/v2-27b442bb0fb1b0305f5013dae67afa4d_720w.jpg)

得到下面多尺度的计算公式：

![img](https://pic4.zhimg.com/80/v2-cff9ad9266191fd2fd68f7a065f83e4b_720w.jpg)

##  2s-AGCN

### 改进点

#### 新的注意力机制

st-gcn中是直接按元素乘以注意力掩码$M_k$，这样无法产生不存在的连接，比如手和脚就无法连接。

![img](https://pic3.zhimg.com/80/v2-dec311d59f527cd000fef8e88d9eb83a_720w.jpg)

2s-AGCN是掩膜（$B_k,C_k$）直接与邻接矩阵$A_k$相加，就可以产生不存在的连接。

![img](https://pic4.zhimg.com/80/v2-9962c9f2e796790624ca3149f9139533_720w.jpg)

#### 双流——增加新的分支

新分支的输入：骨骼的长度和方向。

首先寻找一个人体骨骼的重心，就是**把人胸腔部分作为中心点**，因为每个骨骼都有两个点，**把靠近中心点的关节看做源关节，远离中心点的关节看做目标关节**。所以说关节就是点，骨骼就是从一个点指向另外一个点的向量，**向量的长度就是骨骼的长度，向量的方向就是骨骼的方向**。

细节：

1. joint和bone两个分支的网络结构一样。由于bone比joint少一个，添加一个0使其与joint数目一致，注意就可以使用同一个网络结构了
2. 两个网络都得到了评分，直接评分相加，作为最终评分

## MS-AGCN

### 改进点

#### 自适应图卷积

$$
f_{\text {out }}=\sum_{k}^{K_{v}} W_{k} f_{\text {in }}\left(B_{k}+\alpha C_{k}\right)
$$

在$B_k$前添加一个$1-\alpha$：这样

$B_k$初始为$A_k$：这样使用了先验的连接信息，随着训练逐渐会去除这些先验信息，得到合适的自适应邻接矩阵

自适应是指某些参数自适应，比如上面的$\alpha$就是自适应参数

#### STC注意力模块

SAM：空间注意力机制

TAM：时间注意力机制

CAM：通道注意力机制

都只是用的普通的平均池化，==可以换成CBAM那种==

#### 四流

增加了

前后两帧的关节点位置偏差

前后两帧的骨架向量偏差

## MS-G3D

### 改进点

#### 3D图卷积（同3D卷积）

1. 将串联二维SGCN和TCN，合成了3D的，进而更合理的捕捉跨时空的信息
2. 其中时间维度，使用的空洞卷积，在保证参数量不变的情况下，扩大感受野
3. 同样添加了一个自适应卷积模块，不过是直接和邻接矩阵相加，不像2s-AGCN那么复杂

#### 3D卷积的实现介绍

**3D卷积的实现**

如原来的NCTV的特征图，由于每次卷积直接使用连续3帧的信息，因此复制前后两帧的特征得到了(NCT,3V)的特征，故相当于有3V个结点，所以A直接复制得到一个(3V,3V)的大矩阵，这样就可以对每一个结点提取到3维空间与其相邻的结点信息。

**多尺度实现方法**

计算出A的多阶矩阵（1阶矩阵就是与当前结点距离为1的结点），假设需要5阶矩阵，多尺度信息的提取方法就是修改邻接矩阵，将5个5阶矩阵直接拼接为5V×V的大邻接矩阵A_large
A_large与(NCTV)相乘就可以得到NCT，5V的特征，然后view到N,5C,TV，这样特征中就包含了多阶特征的信息。再进行卷积就相当于提取了多尺度特征

## 参考链接

[【骨骼行为识别】2s-AGCN论文理解](https://zhuanlan.zhihu.com/p/179956749)

[(MS-AGCN)阅读Skeleton-Based Action Recognition with Multi-Stream Adaptive Graph Convolutional Networks](https://blog.csdn.net/qq_33331451/article/details/105274031)
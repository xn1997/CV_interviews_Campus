## 问题

决策树是怎么一步步生成的

## 决策树原理

决策树简单来说就是带有判决规则（if-then）的一种树，可以依据树中的判决规则来预测未知样本的类别和值。

决策树的学习本质上是从训练集中归纳出一组分类规则，得到与数据集矛盾较小的决策树，同时具有很好的泛化能力。决策树学习的**损失函数通常是正则化的极大似然函数**，通常采用启发式方法，近似求解这一最优化问题。

## 决策树生成流程

顾名思义，决策树是一种树结构，一般的，包含一个根节点、若干个内部结点和若干个叶节点。
根节点包含样本全集；叶节点对应着分类结果，即在同一个叶节点中的样本被分类归属为一个类别；而内部结点中的每一个结点对应于属性测试，即当前内部结点是其父结点根据最优属性划分后的一个分支，在当前结点依然可分的情况下，继续寻找最优划分属性并划分为该属性所有取值的个数的分支，至于怎么选择最优划分属性，请参考机器学习文件夹中的问题<u>“20_随机森林思想”</u>。

决策树的生成是一个递归的过程。在决策树的基本算法中，有三种情况会导致**递归返回**：
（1）当前节点包含的样本全属于同一类别，无需划分；
（2）当前节点包含的样本集为空，不能划分。
（3）当前属性集为空，或是所有样本在所有属性上取值相同，无法划分，这时把当前结点标记为叶节点，并将其类别设定为该节点所含样本最多的类别；

## 参考资料

<u>《机器学习》周志华</u>
[决策树原理详解](https://blog.csdn.net/qq_38923076/article/details/82930949)
[决策树模型 ID3/C4.5/CART算法比较](https://www.cnblogs.com/wxquare/p/5379970.html)
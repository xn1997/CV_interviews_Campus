1. 有监督：用有标签的数据训练；
2. 无监督：用无标签的数据训练；
   K-means等
3. 半监督：利用数据分布上的模型假设建立学习器对未标签样例进行标签。通常是两阶段的训练，先用（较小规模的）有标签数据训练一个Teacher模型，再用这个模型对（较大规模的）无标签数据预测伪标签，作为Student模型的训练数据；
   知识蒸馏。
4. 自监督：在无标注数据上训练，通过一些方法让模型学习到数据的inner representation，再接下游任务，例如加一个mlp作为分类器等。但接了下游任务之后还是需要在特定的有标签数据上finetune，只是有时候可以选择把前面的层完全固定，只finetune后面接的网络的参数。
   <u>自监督数据监督来源于数据本身，其实就是自己生成一些简单的标签，然后去学习，理论上网络就学习到了图像的一些特征信息，然后再在这个模型的基础上添加其他任务。</u>
   将图片分割为多个区域并打乱，然后让模型将它还原为原始图片。和拼图游戏很像。
   将图片中部分区域挖空，然后让模型进行预测，使输出能尽量还原输入图片。
   将图片旋转一定角度，让模型预测旋转了多少度。或者将图片旋转0、90、180、270度四种类别，让模型预测旋转的类别。
5. 弱监督：用包含噪声的有标签数据训练。
   标签的强弱指的是标签蕴含的信息量的多少，比如<u>相对于分割的标签来说，分类的标签就是弱标签</u>，如果我们知道一幅图，告诉你图上有一只猪，然后需要你把猪在哪里，猪和背景的分界在哪里找出来，那么这就是一个已知若标签，去学习强标签的弱监督学习问题。
   比如使用一个分类网络，然后加入注意力机制，根据空间注意力的值，获得分割效果。（貌似是什么grad网络）

### 参考链接

[深度学习：基本概要：监督，无监督，半监督，弱监督，多示例，迁移学习](https://blog.csdn.net/weixin_41108334/article/details/82803522)


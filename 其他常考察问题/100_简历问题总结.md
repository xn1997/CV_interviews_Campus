作为知识树，仅供复习使用

# 简历问题

## 扶梯项目

脑图链接：https://naotu.baidu.com/file/202eaa83c1e8c99ce33e742caa9eb7cd

<img src="H:/Application/Typora图片暂存文件夹/扶梯项目-1626164086004.svg" alt="扶梯项目" style="zoom:150%;" />

### 项目中的评价指标

人头检测：mAP，F1-score

人头跟踪：客流量统计准确率（真实数据和检测数据的比例）

### TensorRT使用

1. YOLO和Openpose由于包含了比较多的TensorRT不支持的plugin，所以直接将别人写好的TensorRT版本编译到项目中，直接使用了。
2. 而对于GCN的TensorRT版本，由于相应的仓库不多，且结构简单，就自己进行了转换。
   ①遇到的问题是，TensorRT不支持einsum操作，而网络中邻接矩阵和特征的乘积是通过爱因斯坦求和实现的，所以就自己实现了一个简单的爱因斯坦求和插件。
   ②仿照给的<font color='cornflowerblue'>自定义plugin</font>例程进行改写，期间涉及到矩阵运算，开始的时候有想过使用CPU计算，用for实现，发现推理速度直接变慢了一百多倍。。。后来参考网上的博客发现可以使用cublas库，所以就使用了`cublasSgemm`API完成矩阵运算，速度没有什么变化。
   注意cublas的读入顺序是按列优先的，这与其他API不一样，所以需要借用矩阵转置相关的性质来计算。

### 客流量统计

方案：目标检测+目标跟踪-->得到乘客运动轨迹，从而根据单线计数法统计客流量。

评估标准：给一段视频，只看最后的统计结果和实际的统计结果的比值作为准确率。

#### 使用YOLOv4作为目标检测框架

1. 环境变化-->数据集变化，数据大幅增加

   1. 原先的实验环境十分单一，只是从上往下俯瞰，检测头部信息，特征非常简单，且目标相对来说比较大，模型不用十分复杂，所以自行制作了一个小型的数据集，并使用模型较小的YOLOv3-tiny已经足够取得很好的检测效果。
   2. 需求改变。要求测试环境不再单一，测试环境增加了实际地铁场景，而且包含了多个机位的拍摄视频，这些机位大都是倾斜安装，会检测到人脸、后脑勺，人的服装等而且倾斜角度不同，人头特征也比较复杂；同时背景也很不一样，有室外有室内，亮度也不固定。这些信息在原来自制的数据集中都是没有的，原先的数据集根本无法使用。
   3. 因此，由于实际测试环境发生大幅变化，导致原先的数据集无法使用，而自己制作数据集也无法涵盖所有的场景，且数据量不足，另外即便再已有的数据集上制作了，到时验收环境或许又会不同，因此没有制作数据集的必要。所以直接去<font color='cornflowerblue'>寻找公用的人头检测数据集</font>，并再公用的数据集上训练，并将训练好的模型运用到项目中进行人头检测。
      理论基础：虽然公用数据集与地铁环境有很大不同，但由于数据集背景丰富，且人头的旋转角度、大小千差万别，数据集很丰富，所以模型可以充分学习这些特征。

2. YOLOv4替换YOLOv3-tiny（数据集过大，必须使用特征能力更强的网络）

   1. 数据集很大，一共有4个场景的数据，包括咖啡厅、网络数据（SCUT-A）、教室数据（SCUT-B）、个人标注的5000张地铁楼层板的数据，共一万多张图片，数据集包含的信息过多。
   2. YOLOtiny模型较小，无法充分拟合这么大的数据集，mAP只有50%，而<font color='cornflowerblue'>YOLOv4拟合能力更强</font>，mAP达到91%，因此必须使用特征提取能力更强的网络。

3. 设备性能受限

   1. 为了给openpose让出GPU资源，原先的YOLOtiny直接使用CPU运行，处理时间为10ms，而如今使用YOLOv4处理时间提高到了200ms，实时性不满足。

   2. 为了提高YOLOv4推理速度，方案如下：①使用GPU推理②使用TensorRT推理框架③减少待处理图片的大小④进行模型剪枝，缩小网络大小。

      1. <font color='cornflowerblue'>减少处理图片大小</font>，原先输入图片是412，由于实际场景中用于客流统计的范围较小，人头目标相对较大，图片缩放后对整体检测效果影响不大，所以**图片缩放到224**，推理时间减少到90；

         客流量检测区域是人为设置的，不同场景下该区域的大小和长宽比差异巨大，而原来的方法是直接resize到固定大小，造成图像失真，因此将图像按变化最大的边<font color='cornflowerblue'>同比例缩放</font>，其余部分使用均值填充，这样可以在缩放的同时避免失真。

      2. 使用已有的<font color='cornflowerblue'>TensorRT框架</font>对YOLOv4进行加速推理（这个是已有的仓库），推理时间减少到15ms。
         又尝试使用<font color='cornflowerblue'>INT8量化</font>，速度进一步提升到10ms。

   3. 由于原先<font color='cornflowerblue'>openpose速度同样很慢</font>，200ms以上，由于此时人头检测也使用GPU，而GPU资源有限，这样就导致人头检测的速度严重受openpose的影响，无法实时，因此，必须提高openpose的速度，加速方向也是这两个方面：①输入图片太大480×640②没有使用量化。
      图片改为224，速度变为50ms；INT8量化速度变为20ms。
      此时openpose和YOLO对GPU的资源需求都没有那么大，都可以可以达到实时。

#### 行人跟踪

跟踪算法：kalman滤波根据上一帧获得乘客在当前帧的预测框+KM算法完成预测框与检测框的匹配，进而实现乘客跟踪。

1. KM匹配的代价矩阵使用DIOU替换IOU
   1. 在使用IOU计算代价矩阵时，①当检测框和预测框无交集的时候就都会变成1，无论距离多远他的代价都是一样的，这不是很合理；②而且会造成一个问题，就是当乘客运动比较快时，连续两帧的位置差距变大，导致没有交集，但其实他们之间的框距离是很近的，而使用IOU无法计算这个距离，从而造成了这个乘客的跟踪丢失。
   2. 而使用DIOU加入了框中心点之间的距离，这就可以在IOU为0时仍然可以衡量两个框的距离，这样就可以在后续匹配的过程中调整阈值从而<font color='cornflowerblue'>实现对这类移动较快的乘客的跟踪</font>。
2. 目标遮挡的处理（简单的二次匹配）
   1. 环境元素：摄像机的倾斜安装导致乘客近大远小，从而导致近处乘客完全遮住远处乘客，尤其是在乘客从近往远运动时，容易在跟踪途中被遮挡造成跟踪丢失，从而影响客流量统计准确率。（乘客从远到近被遮挡时，没有办法处理，毕竟连乘客的已知轨迹信息都没有办法获取）改进方向：寻找方法实现行人丢失重现后的跟踪。
   2. <font color='cornflowerblue'>二次匹配</font>：①思考：行人丢失只可能是被另一个乘客的人头遮挡，也就是说此时两个乘客的**运动轨迹在这个位置发生了交叉**，此时两个人头都在同一个位置，而由于此时只检测到一个人头，KM匹配算法又只是一对一匹配，从而造成其中一个人跟踪丢失，进而这个人就无法被客流量所统计。②方案：所以在KM匹配之后，单独对没有跟踪成功的乘客，判断是否存在与其距离十分靠近的目标，如果有，就认为当前这个乘客是被遮挡导致的跟踪丢失，并让这两个目标进行匹配，完成对这个乘客的跟踪。也就是通过这个二次匹配将KM只能一对一匹配，变成了可以**一对多的匹配**，从而缓解跟踪丢失问题；当两个乘客重新分离之后，无需处理KM会自动对两个目标完成跟踪。
      **为什么不使用行人重识别？**：一般解决乘客遮挡的问题，大都使用行人重识别，根据图像信息来对乘客进行遮挡处理，他的缺点：①没有人头的跟踪数据集，无法训练重识别网络，做起来也比较麻烦。②速度：行人重识别网络计算量不是很小，为解决遮挡问题，需要计算检测框与所有乘客在连续多帧的特征相似度，**计算量较大**，可能会对实时性造成较大影响。③效果：行人重识别可以生效的主要原因是目标之间有较大的图像差异，而对于人头检测，尤其是遮挡处理所处的情况，大都是检测到乘客的后脑勺，基本上都是黑色、圆形，**特征不明显**，使用行人重识别很难提取出特征差异，区分不同目标的效果可能并不好。

### 扶手带异物检测

1. 使用GMM进行运动目标检测
   1. 原因：①只要扶手带上有物体伸出就应该检测到，因此**物体的种类无法判断**，所以无法使用监督学习的方法进行物体检测。②异物伸出的判断**属于像素级别的任务**，比如手只要有一部分弹出就应该被检测到。考虑到相对扶手带而言，位于其上面的异物是运动的，所以使用传统的运动目标检测算法，而<font color='cornflowerblue'>GMM相对来说鲁棒性更强</font>一些，所以选用GMM。
   2. 判断异物伸出的规则：手动框定扶手带和扶手带外侧区域，如果两侧的同一水平位置出现运动物体，就视该位置有异物伸出。
2. 对于运动提取结果的自适应过滤
   1. 原因：初步提取的运动物体中，会有大量的噪声点，如果不过滤掉会造成大量的误检。根据观察一般**噪声相比异物宽度窄很多**，因此，考虑根据轮廓宽度来过滤，而阈值的选取很重要。
   2. 自适应阈值：①使用固定阈值的缺点：因为用扶手带异物检测的摄像机是在楼层板上方安装的，得到的扶手带图像也是近大远小，如果阈值太大，那么远处的异物也会被过滤掉造成漏检；阈值太小，近处的噪声过滤不掉，造成误检。②<font color='cornflowerblue'>自适应阈值</font>：因为框定的扶手带区域也是近大远小，因此，设置一个动态阈值，其等于轮廓所在行的扶手带宽度的1/4，这样远处和近处的噪声都可以滤除掉，同时也不会去除正常的异物。

GMM：流程

### 异常行为识别

#### 骨架检测与跟踪

Openpose：结构+PAF+loss。。。

跟踪过程和人头跟踪类似，也是kalman滤波预测每个关节点位置+KM直接根据骨架距离进行匹配

重点是骨架距离的计算方法

1. <font color='cornflowerblue'>结合关节点置信度的骨架距离</font>计算	

   1. ①直接对所有关节位置取平均来计算骨架中心距离的缺点：检测过程中会出现一些误检的骨架，如果不考虑置信度，直接利用骨架中心距离会导致误匹配。因此考虑在骨架距离中引入置信度。

   2. 两两计算对应关节之间的距离：①计算关节点之间的距离L②计算对应关节点置信度均值C③总的距离就是L(1-C)，所有关节取均值。④使用exp(-x)将最终的置信度置于0-1之间
      这样可以反映出置信度越高相似度越高，距离越短相似度越高。
      $$
      K个关节点，第i个关节点之间的距离为L_i，置信度均值为C_i\\
      i个关节点总的距离D_i=\exp\{-L_i(1-C_i)\} \\
      骨架之间的距离=mean(D_i),i=1...K
      $$

#### 行为分类

1. 使用GCN的原因
   1. GCN很适合处理图数据，而且GCN在图的分类中效果比较好。原先使用的SVM，准确率比较低80多，说明SVM不适合捕获关节之间的特征。
   2. 具体改进点，看MS-G3D

# 计算机视觉

## mobilenetV1->v3

1. V1
   1. 深度可分离卷积：过程，计算量和参数量计算
2. V2
   1. 倒残差结构：提高深度卷积提取的信息量。借鉴了ResNet、Densenet的shortcut结构
   2. linear bottleneck结构：将最后一个Relu6换成Linear，防止丢弃过多的信息
   3. 步长=1和=2时，不同的bottleneck。仅仅是否存在shortcut
3. V3
   1. 加入SE结构：显示的增强有益的通道，抑制无用通道。avg Pooling
   2. 提出h-swish激活函数：精度不变，但更容易实现软硬件优化。公式。

## shortcut为什么效果更好

1. 更容易优化

## YOLOv1-v4

描述流程

损失函数写出来

## Cascade RCNN

流程

### DCN

## FPN原理

## anchor free

**CornerNet**
两点贡献：
1.通过检测bbox的一对角点来检测出目标。
2.提出corner pooling，来更好的定位bbox的角点。
**ExtremeNet**
https://zhuanlan.zhihu.com/p/57688629
两个贡献：
1.将关键点定义为极值点。
2.根据几何结构对关键点进行分组

**FCOS**



## 如何避免过拟合

1. BN
2. dropout
3. 正则化
4. 降低模型复杂度
5. 提前终止迭代
6. 数组增强（为训练数据添加噪声）
7. bagging、boosting（多个简单模型组合，不容易过拟合）

## Bagging、Boosting

## BN层

1. 没有BN层会怎么样（为什么要有BN层）

2. 计算过程：normalization+恢复

   1. 恢复：标准化改变了数据原有的信息表达，导致信息丢失，因此进行数据恢复。

3. 预测阶段如何使用：$\mu$使用所有训练batch的均值，$\delta$为所有方差的无偏估计$\frac{m}{m+1}$。

   或者训练时使用滑动平均得到测试阶段的均值和方差估计。

- **如何缓解数据分布不一致问题**
  - 除了BN，还可以使用**白化处理**。如PCA白化：
    1. 使输入特征分布具有相同的均值和方差(0,1)
    2. 去除特征之间的相关性。

## 样本不平衡怎么办

## 损失函数

### CE loss交叉熵损失

**下面二分类的为BCE loss，多分类的为CE loss**：二者都是交叉熵，只不过CE loss去掉了对y=0时的约束，只聚焦于对应类别概率是否为1，而不管其他类是否为0，可行的原因是，CE是结合softmax使用的，所以只要保证对应位置为1，那么其他类必定为0。

![](./image/CEloss.png)

### Triplet loss

查看`比赛介绍.md`

## Adam/SGD/Ranger优化器

参数更新原理

## 梯度下降的步骤

## 深度可分离卷积为什么减少参数量

## attention

SE

CBAM

## 参数初始化的方法

## NMS过程描述

## 卷积操作的具体过程及矩阵优化

## 知识蒸馏、剪枝、模型压缩

# 机器学习

## SVM原理

## LR原理（逻辑回归）

## 决策树原理

## Adaboost/XGBoost/GBDT原理

## 随机森林/Adaboost/GBDT/XGBoost的区别

## 高斯混合模型和K-mean的异同

## K-mean、EM算法以及他们的联系

## PCA、LDA原理及比较

## 什么情况下使用朴素贝叶斯

## PR曲线、ROC曲线、F1-score和AUC如何计算

## 生成模型和判别模型（暂时不用注意）

# 图像处理

## HOG原理

# 编程基础

## C++虚函数、虚指针、虚函数表

## C++智能指针

## python装饰器

## new和int的区别

## 迭代器什么时候使用

## 多态的特性

## 进程和线程的区别（多进程如何实现）

## TCP/IP三次握手、四次挥手的过程

# 算法题

## 归并排序

## 快速排序

## 公共父节点

## 最小子序列

## 判断是否有环

## 链表翻转

### 图的遍历（深度、广度）

### 双指针、滑动窗口

### 查找

### 单调栈

一维数组，

下雨的题